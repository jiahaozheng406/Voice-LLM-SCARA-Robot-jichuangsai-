# Voice-LLM-SCARA-Robot

**智能语音交互与视觉引导 SCARA 机械臂系统**

**项目介绍** 这是一个基于 Python 多线程架构的智能机械臂控制系统，实现了从语音指令到物理执行的全流程自动化。项目融合了 **Coze 平台定制智能体** 的语义理解能力与 **自行训练的 ONNX 模型** 的视觉感知能力。它不依赖封装好的商业控制软件，而是通过手写底层驱动与运动学算法，将大语言模型与边缘侧视觉推理深度结合，能够在本地高效完成桌面物品的分拣与清理任务。

**功能概览** 在交互层，用户通过 Web 前端 `contact2.html` 进行语音或文本输入。后台服务 `LLM_talk_AGENT.py` 充当智能中枢，它通过 API 对接了**我们在 Coze 平台上适配开发的智能体**，能够将模糊的自然语言解析为标准的 JSON 控制帧，实现了精准的意图识别。
在感知层，视觉核心 `detect_new1.py` 加载了**基于 YOLOv5 架构自行训练的 `best_1.onnx` 模型**。该模型基于自建数据集训练而成（**zip**中为部分数据集，涵盖 **Eraser, Scale, Pencil, Sharpener, Paper** 五类常见文具）。
在执行层，主控程序 `run_top.py` 负责全局多线程调度。它调用 `scara_1.py` 中的逆运动学算法将坐标转化为电机脉冲，并通过串口发送给下位机 `v0_1.ino` 实现精准抓取；针对特定任务，`run_1.py` 则封装了自动清理等复杂的连续动作逻辑。

**核心控制模块**

run\_top.py - 主控制程序

机械臂双串口通信管理

指令调度与防冲突保护

超时自动清理机制

支持复位、清理、单个物品抓取指令

LLM\_talk\_AGENT.py - 语音交互服务

HTTP服务器提供Web界面

语音识别 + Coze-DeepSeek智能体对话

语音指令转机械臂控制

音频格式转换与处理

**机械臂控制模块**

scara\_1.py - 机械臂底层驱动

SCARA运动学正逆解计算

串口指令封装与通信

关节空间与笛卡尔空间控制

run\_1.py - 自动清理逻辑

分步抓取放置流程控制

连续物体检测机制

异常处理与安全复位

**视觉识别模块**

detect\_new1.py - 物体检测

YOLOv5 ONNX模型推理

实时摄像头图像处理

桌面物品识别与定位

**前端与资源**

contact2.html - Web交互界面

语音录音与播放功能

实时状态显示

响应式网页设计

**模型**

best\_1.onnx - YOLO检测模型

ONNX格式

基于YOLOv5的自训练模型

输入：640×640 RGB图像

输出：物品类别、坐标位置、置信度

**Arduino(scara.ino)**

SCARA机械臂底层控制程序，负责电机驱动和传感器管理。

硬件控制：

\- 4个步进电机：分别控制机械臂的θ1、θ2、φ旋转关节和Z轴升降

\- 1个伺服电机：控制夹爪的开合动作

\- 4个限位开关：用于各轴的零点定位

通信接口：

\- 串口通信，波特率115200

\- 接收10个逗号分隔的整数指令

\- 支持回零、点位运动等多种控制模式

运动控制：

\- 将角度和距离转换为电机步数

\- 多轴协同运动，确保同步性

\- 实时响应中断指令

\- 自动回零校准功能

状态反馈：每条指令执行完成后返回"DONE"信号，与上位机Python程序形成控制闭环。


**运行说明** 项目核心代码由 Python 编写，下位机为 Arduino C++。运行前请确保安装 `requirements.txt` 中的依赖库，并连接 USB 摄像头与机械臂串口。直接运行 `run_top.py` 即可启动系统，它会自动初始化视觉线程与语音服务。

更加详细的逻辑请见代码注释，如有相关问题和漏洞恳请批评指正。
